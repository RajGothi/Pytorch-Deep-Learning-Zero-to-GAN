{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 73.,  67.,  43.],\n",
       "       [ 91.,  88.,  64.],\n",
       "       [ 87., 134.,  58.],\n",
       "       [102.,  43.,  37.],\n",
       "       [ 69.,  96.,  70.]], dtype=float32)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs = np.array([[73,67,43],[91,88,64],[87,134,58],[102,43,37],[69,96,70]],dtype='float32')\n",
    "inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  56.,   70.],\n",
       "       [  81.,  101.],\n",
       "       [ 119.,  133.],\n",
       "       [  22.,   37.],\n",
       "       [ 103., 1119.]], dtype=float32)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "targets = np.array([[56,70],[81,101],[119,133],[22,37],[103,1119]],dtype=f'float32')\n",
    "targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 73.,  67.,  43.],\n",
      "        [ 91.,  88.,  64.],\n",
      "        [ 87., 134.,  58.],\n",
      "        [102.,  43.,  37.],\n",
      "        [ 69.,  96.,  70.]])\n",
      "tensor([[  56.,   70.],\n",
      "        [  81.,  101.],\n",
      "        [ 119.,  133.],\n",
      "        [  22.,   37.],\n",
      "        [ 103., 1119.]])\n"
     ]
    }
   ],
   "source": [
    "inputs = torch.from_numpy(inputs)\n",
    "targets = torch.from_numpy(targets)\n",
    "print(inputs)\n",
    "print(targets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-0.5583,  0.4737,  0.2916],\n",
      "        [-0.3604,  2.4540,  0.8760]], requires_grad=True)\n",
      "tensor([ 2.0557, -0.4306], requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "w = torch.randn(2,3,requires_grad=True)\n",
    "b= torch.randn(2,requires_grad=True)\n",
    "print(w)\n",
    "print(b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model(x):\n",
    "    return x @ w.t() + b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[  5.5794, 175.3486],\n",
      "        [ 11.6023, 238.7917],\n",
      "        [ 33.8776, 347.8629],\n",
      "        [-23.7305, 100.7454],\n",
      "        [ 29.4244, 271.6079]], grad_fn=<AddBackward0>)\n"
     ]
    }
   ],
   "source": [
    "preds = model(inputs)\n",
    "print(preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mse(target,preds):\n",
    "    diff = preds-target\n",
    "    return torch.sum(diff*diff)/diff.numel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(82049.6562, grad_fn=<DivBackward0>)\n"
     ]
    }
   ],
   "source": [
    "loss = mse(targets,preds)\n",
    "print(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#computer gradients\n",
    "loss.backward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-5428.5566, -5984.2520, -3677.7932],\n",
       "        [-2609.0947, -6126.5889, -6229.6328]])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w.grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'NoneType' object has no attribute 'zero_'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_13728\\2290418081.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      3\u001b[0m     \u001b[0mw\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mw\u001b[0m \u001b[1;33m-\u001b[0m \u001b[1;36m1e-5\u001b[0m \u001b[1;33m*\u001b[0m \u001b[0mw\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgrad\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m     \u001b[0mb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mb\u001b[0m \u001b[1;33m-\u001b[0m \u001b[1;36m1e-5\u001b[0m \u001b[1;33m*\u001b[0m \u001b[0mb\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgrad\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m     \u001b[0mw\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgrad\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mzero_\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      6\u001b[0m     \u001b[0mb\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgrad\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mzero_\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'NoneType' object has no attribute 'zero_'"
     ]
    }
   ],
   "source": [
    "# #it will not calculate the gradient here.\n",
    "with torch.no_grad():\n",
    "    w = w - 1e-5 * w.grad\n",
    "    b = b - 1e-5 * b.grad \n",
    "    w.grad.zero_()\n",
    "    b.grad.zero_()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# preds = model(inputs)\n",
    "# loss = mse(preds,targets)\n",
    "# print(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0., 0., 0.],\n",
      "        [0., 0., 0.]])\n",
      "tensor([0., 0.])\n"
     ]
    }
   ],
   "source": [
    "print(w.grad)\n",
    "print(b.grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[-0.0264, -0.9996,  0.0738],\n",
       "         [ 0.6890,  1.3516, -1.1693]]),\n",
       " tensor([-0.7118, -1.2952]))"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nw,nb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import torch\n",
    "\n",
    "# # Assuming you have initialized w and b as torch Tensors\n",
    "# w = torch.randn(10, requires_grad=True)\n",
    "# b = torch.randn(1, requires_grad=True)\n",
    "\n",
    "# # Forward pass and loss computation\n",
    "# x = torch.randn(10)\n",
    "# y = torch.randn(1)\n",
    "# output = torch.matmul(x, w) + b\n",
    "# loss = torch.nn.functional.mse_loss(output, y)\n",
    "\n",
    "# # Backward pass and gradient computation\n",
    "# loss.backward()\n",
    "\n",
    "# # Zero out the gradients\n",
    "# w.grad.data.zero_()\n",
    "# b.grad.data.zero_()\n",
    "\n",
    "# # Print the gradients\n",
    "# print(w.grad)\n",
    "# print(b.grad)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "element 0 of tensors does not require grad and does not have a grad_fn",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_13728\\596454440.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      3\u001b[0m     \u001b[0mpreds\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m     \u001b[0mloss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmse\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpreds\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtargets\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m     \u001b[0mloss\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      6\u001b[0m     \u001b[1;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mno_grad\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m         \u001b[0mw\u001b[0m \u001b[1;33m-=\u001b[0m \u001b[0mw\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgrad\u001b[0m \u001b[1;33m*\u001b[0m \u001b[1;36m1e-5\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\torch\\_tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[1;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[0;32m    485\u001b[0m                 \u001b[0minputs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    486\u001b[0m             )\n\u001b[1;32m--> 487\u001b[1;33m         torch.autograd.backward(\n\u001b[0m\u001b[0;32m    488\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    489\u001b[0m         )\n",
      "\u001b[1;32mc:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\torch\\autograd\\__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[1;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[0;32m    198\u001b[0m     \u001b[1;31m# some Python versions print out the first line of a multi-line function\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    199\u001b[0m     \u001b[1;31m# calls in the traceback and some print out the last line\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 200\u001b[1;33m     Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n\u001b[0m\u001b[0;32m    201\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgrad_tensors_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    202\u001b[0m         allow_unreachable=True, accumulate_grad=True)  # Calls into the C++ engine to run the backward pass\n",
      "\u001b[1;31mRuntimeError\u001b[0m: element 0 of tensors does not require grad and does not have a grad_fn"
     ]
    }
   ],
   "source": [
    "# Train for 100 epochs\n",
    "for i in range(100):\n",
    "    preds = model(inputs)\n",
    "    loss = mse(preds, targets)\n",
    "    loss.backward()\n",
    "    with torch.no_grad():\n",
    "        w -= w.grad * 1e-5\n",
    "        b -= b.grad * 1e-5\n",
    "        w.grad.zero_()\n",
    "        b.grad.zero_()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ": 0\n",
      "tensor([[-0.4379],\n",
      "        [-1.7098],\n",
      "        [ 0.2344],\n",
      "        [-0.4372],\n",
      "        [ 1.2280],\n",
      "        [ 0.4308],\n",
      "        [-0.4889],\n",
      "        [ 0.3879],\n",
      "        [-1.5840],\n",
      "        [-0.1759]])\n",
      "tensor([[-1.7472],\n",
      "        [ 0.6198],\n",
      "        [ 0.3186],\n",
      "        [-0.0347],\n",
      "        [-0.1464],\n",
      "        [-0.9215],\n",
      "        [ 0.5389],\n",
      "        [-1.7598],\n",
      "        [ 0.5020],\n",
      "        [ 0.5910]])\n",
      "tensor([[-1.8638],\n",
      "        [-0.1720],\n",
      "        [ 0.7008],\n",
      "        [ 0.4989],\n",
      "        [ 0.7896],\n",
      "        [-1.2079],\n",
      "        [-0.4068],\n",
      "        [-1.1943],\n",
      "        [-0.6686],\n",
      "        [-0.5013]])\n",
      "tensor([[ 0.3581],\n",
      "        [-2.0167],\n",
      "        [ 1.3621],\n",
      "        [ 1.3055],\n",
      "        [ 1.6536],\n",
      "        [ 0.8799],\n",
      "        [ 1.4686],\n",
      "        [ 0.5614],\n",
      "        [ 1.5975],\n",
      "        [-0.5874]])\n",
      "tensor([[ 1.4949],\n",
      "        [ 1.0512],\n",
      "        [-1.0411],\n",
      "        [ 0.2907],\n",
      "        [-0.7468],\n",
      "        [ 1.5695],\n",
      "        [-0.4594],\n",
      "        [ 0.0920],\n",
      "        [-0.5955],\n",
      "        [-0.2646]])\n",
      "tensor([[-0.8820],\n",
      "        [ 0.9350],\n",
      "        [-0.8930],\n",
      "        [-0.5727],\n",
      "        [ 0.9188],\n",
      "        [ 0.5537],\n",
      "        [-1.0602],\n",
      "        [-0.4538],\n",
      "        [ 0.0053],\n",
      "        [ 0.9814]])\n",
      "tensor([[ 0.9797],\n",
      "        [-0.3829],\n",
      "        [-0.5611],\n",
      "        [-0.1121],\n",
      "        [-0.1934],\n",
      "        [ 1.5236],\n",
      "        [-0.6772],\n",
      "        [-0.4902],\n",
      "        [ 0.5728],\n",
      "        [-0.3569]])\n",
      "tensor([[ 0.3312],\n",
      "        [-0.6093],\n",
      "        [-0.9252],\n",
      "        [ 0.5802],\n",
      "        [-0.1785],\n",
      "        [-1.0329],\n",
      "        [-1.9678],\n",
      "        [ 0.3279],\n",
      "        [-1.0740],\n",
      "        [ 0.0135]])\n",
      "tensor([[ 0.4861],\n",
      "        [-0.2479],\n",
      "        [ 0.2732],\n",
      "        [-0.3685],\n",
      "        [-0.2670],\n",
      "        [ 3.0493],\n",
      "        [-0.2848],\n",
      "        [-0.9642],\n",
      "        [-0.3201],\n",
      "        [-0.9259]])\n",
      "tensor([[-2.1356],\n",
      "        [-0.3418],\n",
      "        [-0.9762],\n",
      "        [ 0.1947],\n",
      "        [ 0.0067],\n",
      "        [ 0.5300],\n",
      "        [-2.1487],\n",
      "        [ 0.6868],\n",
      "        [ 1.0821],\n",
      "        [ 0.1159]])\n",
      ": 1\n",
      "tensor([[-0.4379],\n",
      "        [-1.7098],\n",
      "        [ 0.2344],\n",
      "        [-0.4372],\n",
      "        [ 1.2280],\n",
      "        [ 0.4308],\n",
      "        [-0.4889],\n",
      "        [ 0.3879],\n",
      "        [-1.5840],\n",
      "        [-0.1759]])\n",
      "tensor([[-1.7472],\n",
      "        [ 0.6198],\n",
      "        [ 0.3186],\n",
      "        [-0.0347],\n",
      "        [-0.1464],\n",
      "        [-0.9215],\n",
      "        [ 0.5389],\n",
      "        [-1.7598],\n",
      "        [ 0.5020],\n",
      "        [ 0.5910]])\n",
      "tensor([[-1.8638],\n",
      "        [-0.1720],\n",
      "        [ 0.7008],\n",
      "        [ 0.4989],\n",
      "        [ 0.7896],\n",
      "        [-1.2079],\n",
      "        [-0.4068],\n",
      "        [-1.1943],\n",
      "        [-0.6686],\n",
      "        [-0.5013]])\n",
      "tensor([[ 0.3581],\n",
      "        [-2.0167],\n",
      "        [ 1.3621],\n",
      "        [ 1.3055],\n",
      "        [ 1.6536],\n",
      "        [ 0.8799],\n",
      "        [ 1.4686],\n",
      "        [ 0.5614],\n",
      "        [ 1.5975],\n",
      "        [-0.5874]])\n",
      "tensor([[ 1.4949],\n",
      "        [ 1.0512],\n",
      "        [-1.0411],\n",
      "        [ 0.2907],\n",
      "        [-0.7468],\n",
      "        [ 1.5695],\n",
      "        [-0.4594],\n",
      "        [ 0.0920],\n",
      "        [-0.5955],\n",
      "        [-0.2646]])\n",
      "tensor([[-0.8820],\n",
      "        [ 0.9350],\n",
      "        [-0.8930],\n",
      "        [-0.5727],\n",
      "        [ 0.9188],\n",
      "        [ 0.5537],\n",
      "        [-1.0602],\n",
      "        [-0.4538],\n",
      "        [ 0.0053],\n",
      "        [ 0.9814]])\n",
      "tensor([[ 0.9797],\n",
      "        [-0.3829],\n",
      "        [-0.5611],\n",
      "        [-0.1121],\n",
      "        [-0.1934],\n",
      "        [ 1.5236],\n",
      "        [-0.6772],\n",
      "        [-0.4902],\n",
      "        [ 0.5728],\n",
      "        [-0.3569]])\n",
      "tensor([[ 0.3312],\n",
      "        [-0.6093],\n",
      "        [-0.9252],\n",
      "        [ 0.5802],\n",
      "        [-0.1785],\n",
      "        [-1.0329],\n",
      "        [-1.9678],\n",
      "        [ 0.3279],\n",
      "        [-1.0740],\n",
      "        [ 0.0135]])\n",
      "tensor([[ 0.4861],\n",
      "        [-0.2479],\n",
      "        [ 0.2732],\n",
      "        [-0.3685],\n",
      "        [-0.2670],\n",
      "        [ 3.0493],\n",
      "        [-0.2848],\n",
      "        [-0.9642],\n",
      "        [-0.3201],\n",
      "        [-0.9259]])\n",
      "tensor([[-2.1356],\n",
      "        [-0.3418],\n",
      "        [-0.9762],\n",
      "        [ 0.1947],\n",
      "        [ 0.0067],\n",
      "        [ 0.5300],\n",
      "        [-2.1487],\n",
      "        [ 0.6868],\n",
      "        [ 1.0821],\n",
      "        [ 0.1159]])\n",
      ": 2\n",
      "tensor([[-0.4379],\n",
      "        [-1.7098],\n",
      "        [ 0.2344],\n",
      "        [-0.4372],\n",
      "        [ 1.2280],\n",
      "        [ 0.4308],\n",
      "        [-0.4889],\n",
      "        [ 0.3879],\n",
      "        [-1.5840],\n",
      "        [-0.1759]])\n",
      "tensor([[-1.7472],\n",
      "        [ 0.6198],\n",
      "        [ 0.3186],\n",
      "        [-0.0347],\n",
      "        [-0.1464],\n",
      "        [-0.9215],\n",
      "        [ 0.5389],\n",
      "        [-1.7598],\n",
      "        [ 0.5020],\n",
      "        [ 0.5910]])\n",
      "tensor([[-1.8638],\n",
      "        [-0.1720],\n",
      "        [ 0.7008],\n",
      "        [ 0.4989],\n",
      "        [ 0.7896],\n",
      "        [-1.2079],\n",
      "        [-0.4068],\n",
      "        [-1.1943],\n",
      "        [-0.6686],\n",
      "        [-0.5013]])\n",
      "tensor([[ 0.3581],\n",
      "        [-2.0167],\n",
      "        [ 1.3621],\n",
      "        [ 1.3055],\n",
      "        [ 1.6536],\n",
      "        [ 0.8799],\n",
      "        [ 1.4686],\n",
      "        [ 0.5614],\n",
      "        [ 1.5975],\n",
      "        [-0.5874]])\n",
      "tensor([[ 1.4949],\n",
      "        [ 1.0512],\n",
      "        [-1.0411],\n",
      "        [ 0.2907],\n",
      "        [-0.7468],\n",
      "        [ 1.5695],\n",
      "        [-0.4594],\n",
      "        [ 0.0920],\n",
      "        [-0.5955],\n",
      "        [-0.2646]])\n",
      "tensor([[-0.8820],\n",
      "        [ 0.9350],\n",
      "        [-0.8930],\n",
      "        [-0.5727],\n",
      "        [ 0.9188],\n",
      "        [ 0.5537],\n",
      "        [-1.0602],\n",
      "        [-0.4538],\n",
      "        [ 0.0053],\n",
      "        [ 0.9814]])\n",
      "tensor([[ 0.9797],\n",
      "        [-0.3829],\n",
      "        [-0.5611],\n",
      "        [-0.1121],\n",
      "        [-0.1934],\n",
      "        [ 1.5236],\n",
      "        [-0.6772],\n",
      "        [-0.4902],\n",
      "        [ 0.5728],\n",
      "        [-0.3569]])\n",
      "tensor([[ 0.3312],\n",
      "        [-0.6093],\n",
      "        [-0.9252],\n",
      "        [ 0.5802],\n",
      "        [-0.1785],\n",
      "        [-1.0329],\n",
      "        [-1.9678],\n",
      "        [ 0.3279],\n",
      "        [-1.0740],\n",
      "        [ 0.0135]])\n",
      "tensor([[ 0.4861],\n",
      "        [-0.2479],\n",
      "        [ 0.2732],\n",
      "        [-0.3685],\n",
      "        [-0.2670],\n",
      "        [ 3.0493],\n",
      "        [-0.2848],\n",
      "        [-0.9642],\n",
      "        [-0.3201],\n",
      "        [-0.9259]])\n",
      "tensor([[-2.1356],\n",
      "        [-0.3418],\n",
      "        [-0.9762],\n",
      "        [ 0.1947],\n",
      "        [ 0.0067],\n",
      "        [ 0.5300],\n",
      "        [-2.1487],\n",
      "        [ 0.6868],\n",
      "        [ 1.0821],\n",
      "        [ 0.1159]])\n",
      ": 3\n",
      "tensor([[-0.4379],\n",
      "        [-1.7098],\n",
      "        [ 0.2344],\n",
      "        [-0.4372],\n",
      "        [ 1.2280],\n",
      "        [ 0.4308],\n",
      "        [-0.4889],\n",
      "        [ 0.3879],\n",
      "        [-1.5840],\n",
      "        [-0.1759]])\n",
      "tensor([[-1.7472],\n",
      "        [ 0.6198],\n",
      "        [ 0.3186],\n",
      "        [-0.0347],\n",
      "        [-0.1464],\n",
      "        [-0.9215],\n",
      "        [ 0.5389],\n",
      "        [-1.7598],\n",
      "        [ 0.5020],\n",
      "        [ 0.5910]])\n",
      "tensor([[-1.8638],\n",
      "        [-0.1720],\n",
      "        [ 0.7008],\n",
      "        [ 0.4989],\n",
      "        [ 0.7896],\n",
      "        [-1.2079],\n",
      "        [-0.4068],\n",
      "        [-1.1943],\n",
      "        [-0.6686],\n",
      "        [-0.5013]])\n",
      "tensor([[ 0.3581],\n",
      "        [-2.0167],\n",
      "        [ 1.3621],\n",
      "        [ 1.3055],\n",
      "        [ 1.6536],\n",
      "        [ 0.8799],\n",
      "        [ 1.4686],\n",
      "        [ 0.5614],\n",
      "        [ 1.5975],\n",
      "        [-0.5874]])\n",
      "tensor([[ 1.4949],\n",
      "        [ 1.0512],\n",
      "        [-1.0411],\n",
      "        [ 0.2907],\n",
      "        [-0.7468],\n",
      "        [ 1.5695],\n",
      "        [-0.4594],\n",
      "        [ 0.0920],\n",
      "        [-0.5955],\n",
      "        [-0.2646]])\n",
      "tensor([[-0.8820],\n",
      "        [ 0.9350],\n",
      "        [-0.8930],\n",
      "        [-0.5727],\n",
      "        [ 0.9188],\n",
      "        [ 0.5537],\n",
      "        [-1.0602],\n",
      "        [-0.4538],\n",
      "        [ 0.0053],\n",
      "        [ 0.9814]])\n",
      "tensor([[ 0.9797],\n",
      "        [-0.3829],\n",
      "        [-0.5611],\n",
      "        [-0.1121],\n",
      "        [-0.1934],\n",
      "        [ 1.5236],\n",
      "        [-0.6772],\n",
      "        [-0.4902],\n",
      "        [ 0.5728],\n",
      "        [-0.3569]])\n",
      "tensor([[ 0.3312],\n",
      "        [-0.6093],\n",
      "        [-0.9252],\n",
      "        [ 0.5802],\n",
      "        [-0.1785],\n",
      "        [-1.0329],\n",
      "        [-1.9678],\n",
      "        [ 0.3279],\n",
      "        [-1.0740],\n",
      "        [ 0.0135]])\n",
      "tensor([[ 0.4861],\n",
      "        [-0.2479],\n",
      "        [ 0.2732],\n",
      "        [-0.3685],\n",
      "        [-0.2670],\n",
      "        [ 3.0493],\n",
      "        [-0.2848],\n",
      "        [-0.9642],\n",
      "        [-0.3201],\n",
      "        [-0.9259]])\n",
      "tensor([[-2.1356],\n",
      "        [-0.3418],\n",
      "        [-0.9762],\n",
      "        [ 0.1947],\n",
      "        [ 0.0067],\n",
      "        [ 0.5300],\n",
      "        [-2.1487],\n",
      "        [ 0.6868],\n",
      "        [ 1.0821],\n",
      "        [ 0.1159]])\n",
      ": 4\n",
      "tensor([[-0.4379],\n",
      "        [-1.7098],\n",
      "        [ 0.2344],\n",
      "        [-0.4372],\n",
      "        [ 1.2280],\n",
      "        [ 0.4308],\n",
      "        [-0.4889],\n",
      "        [ 0.3879],\n",
      "        [-1.5840],\n",
      "        [-0.1759]])\n",
      "tensor([[-1.7472],\n",
      "        [ 0.6198],\n",
      "        [ 0.3186],\n",
      "        [-0.0347],\n",
      "        [-0.1464],\n",
      "        [-0.9215],\n",
      "        [ 0.5389],\n",
      "        [-1.7598],\n",
      "        [ 0.5020],\n",
      "        [ 0.5910]])\n",
      "tensor([[-1.8638],\n",
      "        [-0.1720],\n",
      "        [ 0.7008],\n",
      "        [ 0.4989],\n",
      "        [ 0.7896],\n",
      "        [-1.2079],\n",
      "        [-0.4068],\n",
      "        [-1.1943],\n",
      "        [-0.6686],\n",
      "        [-0.5013]])\n",
      "tensor([[ 0.3581],\n",
      "        [-2.0167],\n",
      "        [ 1.3621],\n",
      "        [ 1.3055],\n",
      "        [ 1.6536],\n",
      "        [ 0.8799],\n",
      "        [ 1.4686],\n",
      "        [ 0.5614],\n",
      "        [ 1.5975],\n",
      "        [-0.5874]])\n",
      "tensor([[ 1.4949],\n",
      "        [ 1.0512],\n",
      "        [-1.0411],\n",
      "        [ 0.2907],\n",
      "        [-0.7468],\n",
      "        [ 1.5695],\n",
      "        [-0.4594],\n",
      "        [ 0.0920],\n",
      "        [-0.5955],\n",
      "        [-0.2646]])\n",
      "tensor([[-0.8820],\n",
      "        [ 0.9350],\n",
      "        [-0.8930],\n",
      "        [-0.5727],\n",
      "        [ 0.9188],\n",
      "        [ 0.5537],\n",
      "        [-1.0602],\n",
      "        [-0.4538],\n",
      "        [ 0.0053],\n",
      "        [ 0.9814]])\n",
      "tensor([[ 0.9797],\n",
      "        [-0.3829],\n",
      "        [-0.5611],\n",
      "        [-0.1121],\n",
      "        [-0.1934],\n",
      "        [ 1.5236],\n",
      "        [-0.6772],\n",
      "        [-0.4902],\n",
      "        [ 0.5728],\n",
      "        [-0.3569]])\n",
      "tensor([[ 0.3312],\n",
      "        [-0.6093],\n",
      "        [-0.9252],\n",
      "        [ 0.5802],\n",
      "        [-0.1785],\n",
      "        [-1.0329],\n",
      "        [-1.9678],\n",
      "        [ 0.3279],\n",
      "        [-1.0740],\n",
      "        [ 0.0135]])\n",
      "tensor([[ 0.4861],\n",
      "        [-0.2479],\n",
      "        [ 0.2732],\n",
      "        [-0.3685],\n",
      "        [-0.2670],\n",
      "        [ 3.0493],\n",
      "        [-0.2848],\n",
      "        [-0.9642],\n",
      "        [-0.3201],\n",
      "        [-0.9259]])\n",
      "tensor([[-2.1356],\n",
      "        [-0.3418],\n",
      "        [-0.9762],\n",
      "        [ 0.1947],\n",
      "        [ 0.0067],\n",
      "        [ 0.5300],\n",
      "        [-2.1487],\n",
      "        [ 0.6868],\n",
      "        [ 1.0821],\n",
      "        [ 0.1159]])\n",
      "Predicted outputs for test input:\n",
      "tensor([[0.9939],\n",
      "        [1.7883],\n",
      "        [2.5826]], grad_fn=<AddmmBackward0>)\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "# Define custom dataset\n",
    "class CustomDataset(Dataset):\n",
    "    def __init__(self):\n",
    "        self.x = torch.randn(100, 1)  # Random input features\n",
    "        self.y = 3 * self.x + 1       # y = 3x + 1\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.x)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.x[idx], self.y[idx]\n",
    "\n",
    "# Define the linear regression model\n",
    "class LinearRegression(nn.Module):\n",
    "    def __init__(self, input_size, output_size):\n",
    "        super(LinearRegression, self).__init__()\n",
    "        self.linear = nn.Linear(input_size, output_size)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.linear(x)\n",
    "\n",
    "# Create the model instance\n",
    "input_size = 1   # Number of features\n",
    "output_size = 1  # Number of outputs\n",
    "model = LinearRegression(input_size, output_size)\n",
    "\n",
    "# Define the loss function and optimizer\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.01)\n",
    "\n",
    "# Create a custom dataset\n",
    "dataset = CustomDataset()\n",
    "\n",
    "#The most important argument of DataLoader constructor is dataset, which indicates a dataset object to load data from.\n",
    "\n",
    "# Create a data loader\n",
    "batch_size = 10\n",
    "dataloader = DataLoader(dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "# Training loop\n",
    "num_epochs = 5\n",
    "for epoch in range(num_epochs):\n",
    "    print(\":\",epoch)\n",
    "    for batch_x, batch_y in dataloader:\n",
    "        # Forward pass\n",
    "        print(batch_x)\n",
    "        outputs = model(batch_x)\n",
    "        loss = criterion(outputs, batch_y)\n",
    "\n",
    "        # Backward pass and optimization\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    # Print the loss every 10 epochs\n",
    "    if (epoch+1) % 10 == 0:\n",
    "        print(f'Epoch [{epoch+1}/{num_epochs}], Loss: {loss.item():.4f}')\n",
    "\n",
    "# Test the model with new inputs\n",
    "test_input = torch.tensor([[0.5], [1.0], [1.5]])\n",
    "predicted_output = model(test_input)\n",
    "print(\"Predicted outputs for test input:\")\n",
    "print(predicted_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\sklearn\\utils\\deprecation.py:87: FutureWarning: Function load_boston is deprecated; `load_boston` is deprecated in 1.0 and will be removed in 1.2.\n",
      "\n",
      "    The Boston housing prices dataset has an ethical problem. You can refer to\n",
      "    the documentation of this function for further details.\n",
      "\n",
      "    The scikit-learn maintainers therefore strongly discourage the use of this\n",
      "    dataset unless the purpose of the code is to study and educate about\n",
      "    ethical issues in data science and machine learning.\n",
      "\n",
      "    In this special case, you can fetch the dataset from the original\n",
      "    source::\n",
      "\n",
      "        import pandas as pd\n",
      "        import numpy as np\n",
      "\n",
      "\n",
      "        data_url = \"http://lib.stat.cmu.edu/datasets/boston\"\n",
      "        raw_df = pd.read_csv(data_url, sep=\"\\s+\", skiprows=22, header=None)\n",
      "        data = np.hstack([raw_df.values[::2, :], raw_df.values[1::2, :2]])\n",
      "        target = raw_df.values[1::2, 2]\n",
      "\n",
      "    Alternative datasets include the California housing dataset (i.e.\n",
      "    :func:`~sklearn.datasets.fetch_california_housing`) and the Ames housing\n",
      "    dataset. You can load the datasets as follows::\n",
      "\n",
      "        from sklearn.datasets import fetch_california_housing\n",
      "        housing = fetch_california_housing()\n",
      "\n",
      "    for the California housing dataset and::\n",
      "\n",
      "        from sklearn.datasets import fetch_openml\n",
      "        housing = fetch_openml(name=\"house_prices\", as_frame=True)\n",
      "\n",
      "    for the Ames housing dataset.\n",
      "    \n",
      "  warnings.warn(msg, category=FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[6.3200e-03 1.8000e+01 2.3100e+00 ... 1.5300e+01 3.9690e+02 4.9800e+00]\n",
      " [2.7310e-02 0.0000e+00 7.0700e+00 ... 1.7800e+01 3.9690e+02 9.1400e+00]\n",
      " [2.7290e-02 0.0000e+00 7.0700e+00 ... 1.7800e+01 3.9283e+02 4.0300e+00]\n",
      " ...\n",
      " [6.0760e-02 0.0000e+00 1.1930e+01 ... 2.1000e+01 3.9690e+02 5.6400e+00]\n",
      " [1.0959e-01 0.0000e+00 1.1930e+01 ... 2.1000e+01 3.9345e+02 6.4800e+00]\n",
      " [4.7410e-02 0.0000e+00 1.1930e+01 ... 2.1000e+01 3.9690e+02 7.8800e+00]]\n",
      "Epoch [10/100], Loss: 11.2264\n",
      "Epoch [20/100], Loss: 37.0186\n",
      "Epoch [30/100], Loss: 18.9747\n",
      "Epoch [40/100], Loss: 40.8983\n",
      "Epoch [50/100], Loss: 22.3805\n",
      "Epoch [60/100], Loss: 9.1215\n",
      "Epoch [70/100], Loss: 11.9530\n",
      "Epoch [80/100], Loss: 17.4342\n",
      "Epoch [90/100], Loss: 24.9084\n",
      "Epoch [100/100], Loss: 43.3211\n",
      "Predicted outputs for test input:\n",
      "tensor([[29.9812],\n",
      "        [24.8600],\n",
      "        [30.3553],\n",
      "        [28.3803],\n",
      "        [27.7190]], grad_fn=<AddmmBackward0>)\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from sklearn.datasets import load_boston\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Load the Boston Housing dataset\n",
    "boston = load_boston()\n",
    "\n",
    "# print(boston.data)\n",
    "# Preprocess the dataset\n",
    "scaler = StandardScaler()\n",
    "data = scaler.fit_transform(boston.data)\n",
    "target = boston.target\n",
    "\n",
    "# Create custom dataset\n",
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, data, target):\n",
    "        self.x = torch.tensor(data, dtype=torch.float32)\n",
    "        self.y = torch.tensor(target, dtype=torch.float32).view(-1, 1)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.x)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.x[idx], self.y[idx]\n",
    "\n",
    "# Create the model\n",
    "model = nn.Linear(data.shape[1], 1)\n",
    "\n",
    "# Create the loss function and optimizer\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.01)\n",
    "\n",
    "# Create the custom dataset and data loader\n",
    "dataset = CustomDataset(data, target)\n",
    "dataloader = DataLoader(dataset, batch_size=32, shuffle=True)\n",
    "\n",
    "# Training loop\n",
    "num_epochs = 100\n",
    "for epoch in range(num_epochs):\n",
    "    for batch_x, batch_y in dataloader:\n",
    "        # Forward pass\n",
    "        outputs = model(batch_x)\n",
    "        loss = criterion(outputs, batch_y)\n",
    "\n",
    "        # Backward pass and optimization\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    # Print the loss every 10 epochs\n",
    "    if (epoch+1) % 10 == 0:\n",
    "        print(f'Epoch [{epoch+1}/{num_epochs}], Loss: {loss.item():.4f}')\n",
    "\n",
    "# Test the model with new inputs\n",
    "test_input = torch.tensor(data[:5], dtype=torch.float32)\n",
    "predicted_output = model(test_input)\n",
    "print(\"Predicted outputs for test input:\")\n",
    "print(predicted_output)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [10/100], Loss: 0.5730\n",
      "Epoch [20/100], Loss: 0.8416\n",
      "Epoch [30/100], Loss: 0.7204\n",
      "Epoch [40/100], Loss: 0.5919\n",
      "Epoch [50/100], Loss: 0.5749\n",
      "Epoch [60/100], Loss: 0.5111\n",
      "Epoch [70/100], Loss: 0.5730\n",
      "Epoch [80/100], Loss: 0.6785\n",
      "Epoch [90/100], Loss: 0.2913\n",
      "Epoch [100/100], Loss: 0.2517\n",
      "Predicted outputs for test input:\n",
      "tensor([[4.1633],\n",
      "        [3.9674],\n",
      "        [3.7032],\n",
      "        [3.2466],\n",
      "        [2.3648]], grad_fn=<AddmmBackward0>)\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from sklearn.datasets import fetch_california_housing\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Load the California Housing dataset\n",
    "california_housing = fetch_california_housing()\n",
    "\n",
    "# Preprocess the dataset\n",
    "scaler = StandardScaler()\n",
    "data = scaler.fit_transform(california_housing.data)\n",
    "target = california_housing.target\n",
    "\n",
    "# Create custom dataset\n",
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, data, target):\n",
    "        self.x = torch.tensor(data, dtype=torch.float32)\n",
    "        self.y = torch.tensor(target, dtype=torch.float32).view(-1, 1)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.x)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.x[idx], self.y[idx]\n",
    "\n",
    "# Create the model\n",
    "model = nn.Linear(data.shape[1], 1)\n",
    "\n",
    "# Create the loss function and optimizer\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.0001)\n",
    "\n",
    "# Create the custom dataset and data loader\n",
    "dataset = CustomDataset(data, target)\n",
    "dataloader = DataLoader(dataset, batch_size=32, shuffle=True)\n",
    "\n",
    "# Training loop\n",
    "num_epochs = 100\n",
    "for epoch in range(num_epochs):\n",
    "    for batch_x, batch_y in dataloader:\n",
    "        # Forward pass\n",
    "        outputs = model(batch_x)\n",
    "        loss = criterion(outputs, batch_y)\n",
    "\n",
    "        # Backward pass and optimization\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    # Print the loss every 10 epochs\n",
    "    if (epoch+1) % 10 == 0:\n",
    "        print(f'Epoch [{epoch+1}/{num_epochs}], Loss: {loss.item():.4f}')\n",
    "\n",
    "# Test the model with new inputs\n",
    "test_input = torch.tensor(data[:5], dtype=torch.float32)\n",
    "predicted_output = model(test_input)\n",
    "print(\"Predicted outputs for test input:\")\n",
    "print(predicted_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
